{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import hfst\n",
    "import json\n",
    "import sys\n",
    "import morfessor\n",
    "from tags import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from segment import segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage and mean ambiguity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate ```coverage``` and ```mean ambiguity``` for different corpora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../ && ./test_res.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file with wordforms and corresponding glosses with frequency from Siberian Lang:  \n",
    "e.g. \n",
    "```\"одяндэ\": {\"сделать-IPFV-NFUT-2SG\": 4,\n",
    "               \"стать-FUTCNT-2SG\": 1}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('siblang_tags.json', 'r', encoding='utf-8') as f:\n",
    "     wordforms = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the mapping between glosses and tags from the transducer:   \n",
    "e.g. ```\"1SG\": [[\"<p1>\", \"<sg>\"], \"<px1sg>\"]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mapping', 'r', encoding='utf-8') as f:\n",
    "    mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tags(analyser):\n",
    "    \"\"\"\n",
    "    Calculates and prints precision, recall and f-score\n",
    "    in the task of morphological tag assignment.\n",
    "    \n",
    "    :param analyser: a HFST transducer (libhfst.HfstTransducer)\n",
    "    \"\"\"\n",
    "    \n",
    "    tp = fp = fn = not_analysed = skipped = 0\n",
    "\n",
    "    for word in wordforms:\n",
    "        tp, fp, fn, not_analysed, skipped = evaluate_wordform(word,\n",
    "                                                     analyser, mapping,\n",
    "                                                     wordforms[word],\n",
    "                                                     tp, fp, fn,\n",
    "                                                     not_analysed, skipped)\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    fscore = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    print('precision: {:.3%} tp: {} fp: {}'.format(precision, tp, fp))\n",
    "    print('recall: {:.3%} tp: {} fp: {}'.format(recall, tp, fn))\n",
    "    print('fscore: {:.3%}\\n'.format(fscore))\n",
    "    \n",
    "    print('analysed: {:.3%}'.format((len(wordforms) - not_analysed - skipped) / len(wordforms)))\n",
    "    print('not_analysed: {:.3%}'.format(not_analysed / len(wordforms)))\n",
    "    print('skipped: {:.3%}\\n'.format(skipped / len(wordforms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall and f-score of the assignment of morphological tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = hfst.HfstInputStream('../evn.automorf.hfst').read()\n",
    "evaluate_tags(analyser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file with wordforms and corresponding segmentation from Siberian Lang:  \n",
    "e.g. ```\"одяра\": [\"о дя ра\"]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('siblang_segmentation.json', 'r') as f:\n",
    "    siblang_segmentation = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a special file with one wordform in a line for Morfessor segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words_for_segmentation.txt', 'w') as fw:\n",
    "    for word in siblang_segmentation:\n",
    "        fw.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a gold standard file for ```boundary precision and recall``` evaluation ([bpr.py](../blob/master/eval/bpr.py)).  \n",
    "The word and its analyses are separated by a tabular character, any alternative analyses by a comma and a space, and the morphs of the analyses by single space: e.g. ```evening\teven ing, evening```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gold_std_bpr.tsv', 'w') as fw:\n",
    "\n",
    "    for word in siblang_segmentation:\n",
    "        \n",
    "        if len(siblang_segmentation[word]) == 1:\n",
    "            fw.write(word + '\\t' + siblang_segmentation[word][0] + '\\n')\n",
    "            \n",
    "        elif len(siblang_segmentation[word]) > 1:\n",
    "            fw.write(word + '\\t' + ', '.join(siblang_segmentation[word]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate segmentation of the Morfessor recursive model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!morfessor-segment -l model_recursive words_for_segmentation.txt > morfessor_segmentation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('morfessor_segmentation_with_input.tsv', 'w') as fw, \\\n",
    "     open('morfessor_segmentation.txt') as f_morfessor, \\\n",
    "     open('words_for_segmentation.txt') as f_input:\n",
    "        \n",
    "        for w1, w2 in zip(f_input, f_morfessor):\n",
    "            fw.write(w1.strip('\\n') + '\\t' + w2.strip('\\n') + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 bpr.py -g gold_std_bpr.tsv -p morfessor_segmentation_with_input.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate segmentation of the transducer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hfst_segmentation(segmenter):\n",
    "    \"\"\"\n",
    "    Creates a file with segmentation by HFST transducer.\n",
    "    \n",
    "    :param segmenter: a path to the HFST transducer for segmentation (str)\n",
    "                      or HFST transducer (libhfst.HfstTransducer)\n",
    "    \"\"\"\n",
    "    analysed = 0\n",
    "    not_analysed = 0\n",
    "    \n",
    "    with open('hfst_segmentation.tsv', 'w') as fw:\n",
    "\n",
    "        for word in siblang_segmentation:\n",
    "            segmentation = segment(word, segmenter)\n",
    "    \n",
    "            if not segmentation:\n",
    "                not_analysed += 1\n",
    "                continue\n",
    "        \n",
    "            analysed += 1\n",
    "\n",
    "            fw.write(word + '\\t' + ', '.join(segmentation) + '\\n')\n",
    "    \n",
    "    print('analysed: {:.3%}'.format(analysed / (analysed + not_analysed)))\n",
    "    print('not_analysed: {:.3%}'.format(not_analysed / (analysed + not_analysed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segmenter = hfst.HfstInputStream('../dev/segmenter/evn.segmenter.hfst').read()\n",
    "write_hfst_segmentation(segmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 bpr.py -g gold_std_bpr.tsv -p hfst_segmentation.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate segmentation of the Morfessor recursive model using only the words which receive analysis from the transducer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('morfessor_segmentation_part.tsv', 'w') as fw, \\\n",
    "     open('morfessor_segmentation_with_input.tsv') as f_morfessor, \\\n",
    "     open('hfst_segmentation.tsv') as f_hfst:\n",
    "        \n",
    "        hfst_segmented_words = []\n",
    "        \n",
    "        for line in f_hfst:\n",
    "            hfst_segmented_words.append(line.split('\\t')[0])\n",
    "            \n",
    "        for line in f_morfessor:\n",
    "            if line.split('\\t')[0] in hfst_segmented_words:\n",
    "                fw.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 bpr.py -g gold_std_bpr.tsv -p morfessor_segmentation_part.tsv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
