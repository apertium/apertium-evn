{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hfst\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('minlang_wordforms.json', 'r', encoding='utf-8') as f:\n",
    "     wordforms = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mapping', 'r', encoding='utf-8') as f:\n",
    "    mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(wordforms, word, correct, wrong):\n",
    "    analysis = analyser.lookup(word)\n",
    "    res = []\n",
    "    ans = []\n",
    "    for i, elem in enumerate(wordforms[word]):\n",
    "        added = False\n",
    "        if elem:\n",
    "            glosses = elem.strip('-=').replace('=', '-').replace('--', '-').split('-')\n",
    "            added = False\n",
    "            if len(glosses) > 1:\n",
    "\n",
    "                for ana in analysis:\n",
    "                    yes = 0\n",
    "                    for gloss in glosses[1:]:\n",
    "                        m = mapping.get(gloss.upper())\n",
    "\n",
    "                        if isinstance(m, str):\n",
    "                            if m in ana[0]:\n",
    "                                yes += 1\n",
    "                            \n",
    "                        elif isinstance(m, list):\n",
    "                            for item in m:\n",
    "                                if item in ana[0]:\n",
    "                                    yes += 1\n",
    "                                    break\n",
    "\n",
    "                    if yes == len(glosses)-1:\n",
    "                        correct += 1\n",
    "                        res.append(1)\n",
    "                        added = True\n",
    "                        break\n",
    "            else:\n",
    "                res.append(1)\n",
    "                continue\n",
    "            \n",
    "            if not added:\n",
    "                wrong += 1\n",
    "                res.append(0)\n",
    "                ans.append([mapping.get(gloss.upper()) for gloss in glosses[1:]])\n",
    "                \n",
    "    return analysis, res, correct, wrong, ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 4543/7231 0.6282671829622459\n",
      "recall: 5995/8637 0.6941067500289453\n",
      "fscore: 0.659547926098858\n"
     ]
    }
   ],
   "source": [
    "analyser = hfst.HfstInputStream('../evn.automorf.hfst').read()\n",
    "\n",
    "fw = open('minlang_test_results_wrong', 'a')\n",
    "fw.truncate(0)\n",
    "\n",
    "fw_corr = open('minlang_test_results_correct', 'a')\n",
    "fw_corr.truncate(0)\n",
    "\n",
    "recall_true = 0\n",
    "recall_false = 0\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "\n",
    "final_corr = []\n",
    "final_wrong = []\n",
    "\n",
    "for word in wordforms:\n",
    "    \n",
    "    analysis, res, correct, wrong, ans = evaluate(wordforms, word, correct, wrong)\n",
    "    \n",
    "    if not res:\n",
    "        continue\n",
    "    \n",
    "    elif sum(res) != len(wordforms[word]):\n",
    "        recall_false += 1\n",
    "        final_wrong.append(('{}\\t{}/{}\\t{}\\t{}\\t{}\\t{}\\n'.format(word, sum(res),\n",
    "                                                len(wordforms[word]), analysis,\n",
    "                                                wordforms[word], ans,\n",
    "                        max([wordforms[word][elem] for elem in wordforms[word]])),\n",
    "                          max([wordforms[word][elem] for elem in wordforms[word]])))\n",
    "    else:\n",
    "        recall_true += 1\n",
    "        final_corr.append(('{}\\t{}/{}\\t{}\\t{}\\t{}\\n'.format(word, sum(res),\n",
    "                                                len(wordforms[word]), analysis,\n",
    "                                                wordforms[word],\n",
    "                        max([wordforms[word][elem] for elem in wordforms[word]])),\n",
    "                          max([wordforms[word][elem] for elem in wordforms[word]])))\n",
    "\n",
    "fw.write(''.join([x[0] for x in sorted(final_wrong, key=lambda x: x[1], reverse=True)]))       \n",
    "fw_corr.write(''.join([x[0] for x in sorted(final_corr, key=lambda x: x[1], reverse=True)]))       \n",
    "\n",
    "fw.close()\n",
    "fw_corr.close()\n",
    "\n",
    "precision = correct / (correct + wrong)\n",
    "recall = recall_true / (recall_true + recall_false)\n",
    "\n",
    "print('precision: {}/{} {}'.format(correct, (correct + wrong), precision)),\n",
    "print('recall: {}/{} {}'.format(recall_true, (recall_true + recall_false), recall)),\n",
    "print('fscore: {}'.format(2 * (precision * recall) / (precision + recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```precision``` is counted as number of not missing analyses (without incorrect because maybe the annotation has not all the possible analyses)\n",
    "\n",
    "```recall``` is counted as number of analyses where all the analyses from the annotation are in the output of the analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
