{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hfst\n",
    "import json\n",
    "import re\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take words which are analysed by the analyser and have tags in ref.   \n",
    "For each gloss I look at the mapping and if in the mapping it corresponds to:\n",
    "* a single tag with <>, I add this tag to a set with ref tags\n",
    "* a string without <>, I look for this string in test tags and   \n",
    "    if I find a tag with this string -> I remove it from test tags, do tp += 1 and stop  \n",
    "    else -> add this to a set with ref tags\n",
    "* a list, I look for each of the items in test tags  \n",
    "    if I find it -> I remove it from test tags, do tp += 1 and stop  \n",
    "    else -> add this to a set with ref tags\n",
    "    \n",
    "In the end I count:  \n",
    "* ```tp``` as ```len(test tags & ref tags)```\n",
    "* ```fp``` as ```len(test tags - ref tags)```\n",
    "* ```fn``` as ```len(ref tags - test tags)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('minlang_wordforms.json', 'r', encoding='utf-8') as f:\n",
    "     wordforms = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mapping', 'r', encoding='utf-8') as f:\n",
    "    mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_word(word, glosses, tp, fp, fn, not_analysed, skipped):\n",
    "    \n",
    "    analysis = analyser.lookup(word)\n",
    "#     print(analysis)\n",
    "    \n",
    "    if not analysis:\n",
    "        not_analysed += 1\n",
    "        return tp, fp, fn, not_analysed, skipped\n",
    "\n",
    "    # make a set with all test tags\n",
    "    test_tags = list(chain.from_iterable(ana[0].split('<')[2:]\n",
    "                       for ana in analysis))\n",
    "\n",
    "    for i, tag in enumerate(test_tags):\n",
    "        test_tags[i] = '<' + tag\n",
    "        \n",
    "    test_tags = set(test_tags)\n",
    "    \n",
    "    # make a set with all ref tags\n",
    "    ref_tags = set()\n",
    "    for gloss in glosses:\n",
    "        if '-' in gloss or '=' in gloss:\n",
    "            ref_tags_splitted = gloss.strip('-=').replace('=', '-').replace('--', '-').split('-')\n",
    "\n",
    "            # add the first tag to ref tags if it is not a translation\n",
    "            if re.search('NEG|\\d(SG|PL)|FOC', ref_tags_splitted[0].upper()):\n",
    "                ref_tags.add(ref_tags_splitted[0])\n",
    "\n",
    "            ref_tags.update(ref_tags_splitted[1:])\n",
    "        \n",
    "        # add the tag to ref tags if it is not a translation\n",
    "        elif re.search('NEG|\\d(SG|PL)|FOC', gloss.upper()):\n",
    "            ref_tags.add(gloss)\n",
    "                       \n",
    "        else:               \n",
    "            skipped += 1\n",
    "            return tp, fp, fn, not_analysed, skipped\n",
    "    \n",
    "    ref_tags_mapped = set()\n",
    "    \n",
    "    for gloss in ref_tags:\n",
    "        try:\n",
    "            ref_tag = mapping[gloss.upper()]\n",
    "        except:\n",
    "            print(gloss.upper())\n",
    "            continue\n",
    "\n",
    "        if isinstance(ref_tag, str):\n",
    "            n = ref_tag.count('>')\n",
    "\n",
    "            # if a mapping doesn't contain <> \n",
    "            # then we should look for a test tag that contains this string in mapping\n",
    "            # (this is for glosses like CONV that can correspond to any of the converbs)\n",
    "\n",
    "            if n == 0:\n",
    "                added = False\n",
    "                for test_tag in test_tags:\n",
    "                    if ref_tag in test_tag:\n",
    "                        test_tags.remove(test_tag)\n",
    "                        tp += 1\n",
    "                        added = True\n",
    "                        break\n",
    "                \n",
    "                # if < isn't found then add to ref_tags_mapped \n",
    "                # to count the difference between test and ref in the end\n",
    "                if not added:\n",
    "                    ref_tags_mapped.add(ref_tag)\n",
    "\n",
    "            # if a mapping contains one <\n",
    "            # it can directly correspond to a test tag \n",
    "            # so add to ref_tags_mapped\n",
    "            \n",
    "            elif n == 1:\n",
    "                ref_tags_mapped.add(ref_tag)\n",
    " \n",
    "            # if there are more than one tags in mapping\n",
    "            # we should split it\n",
    "            # (for example, 1PL(EXCL).ACC corresponds to <p1><pe><acc><def>)\n",
    "    \n",
    "            elif n > 1:\n",
    "                ref_tags_splitted = ref_tag.split('>')\n",
    "                ref_tags_splitted.remove('')\n",
    "                for tag in ref_tags_splitted:\n",
    "                    tag = tag + '>'\n",
    "                    if tag in test_tags:\n",
    "                        test_tags.remove(tag)\n",
    "                        tp += 1\n",
    "                    else:\n",
    "                        \n",
    "                        # if it isn't found then add to ref_tags_mapped \n",
    "                        # to count the difference between test and ref in the end\n",
    "                        \n",
    "                        ref_tags_mapped.add(tag)\n",
    " \n",
    "        # if a mapping can correspond to more than one tag\n",
    "        # then we should check these tags in test\n",
    "        # (for example, 1SG can correspond to <p1><sg> or to <px1sg>)\n",
    "\n",
    "        elif isinstance(ref_tag, list):\n",
    "            added = False\n",
    "            for item in ref_tag:\n",
    "                if item in test_tags:\n",
    "                    test_tags.remove(item)\n",
    "                    tp += 1\n",
    "                    added = True\n",
    "                    break\n",
    "\n",
    "            if not added:\n",
    "                fn += 1\n",
    "\n",
    "    tp += len(test_tags & ref_tags_mapped)\n",
    "    fp += len(test_tags - ref_tags_mapped)\n",
    "    fn += len(ref_tags_mapped - test_tags)\n",
    "    \n",
    "    return tp, fp, fn, not_analysed, skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(analyser):\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    skipped = 0\n",
    "    not_analysed = 0\n",
    "\n",
    "    for word in wordforms:\n",
    "        tp, fp, fn, not_analysed, skipped = evaluate_word(word,\n",
    "                                                     wordforms[word],\n",
    "                                                     tp, fp, fn,\n",
    "                                                     not_analysed, skipped)\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    fscore = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print('precision: {:.3%} tp: {} fp: {}'.format(precision, tp, fp)),\n",
    "    print('recall: {:.3%} tp: {} fp: {}'.format(recall, tp, fn)),\n",
    "    print('fscore: {:.3%}\\n'.format(fscore))\n",
    "\n",
    "    print('analysed: {:.3%}'.format((len(wordforms) - not_analysed - skipped) / len(wordforms)))\n",
    "    print('not_analysed: {:.3%}'.format(not_analysed / len(wordforms)))\n",
    "    print('skipped: {:.3%}'.format(skipped / len(wordforms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 29.281% tp: 5595 fp: 13513\n",
      "recall: 76.195% tp: 5595 fp: 1748\n",
      "fscore: 42.305%\n",
      "\n",
      "analysed: 44.440%\n",
      "not_analysed: 44.900%\n",
      "skipped: 10.660%\n"
     ]
    }
   ],
   "source": [
    "# everything is counted only for the words for which the analysis was given\n",
    "# and which contain tags in ref (words without affixes are skipped)\n",
    "\n",
    "analyser = hfst.HfstInputStream('../evn.automorf.hfst').read()\n",
    "evaluate(analyser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 28.450% tp: 10037 fp: 25243\n",
      "recall: 79.957% tp: 10037 fp: 2516\n",
      "fscore: 41.967%\n",
      "\n",
      "analysed: 71.191%\n",
      "not_analysed: 17.932%\n",
      "skipped: 10.877%\n"
     ]
    }
   ],
   "source": [
    "# everything is counted only for the words for which the analysis was given\n",
    "# and which contain tags in ref (words without affixes are skipped)\n",
    "\n",
    "# relaxed\n",
    "analyser_relaxed = hfst.HfstInputStream('../evn_relaxed.automorf.hfst').read()\n",
    "evaluate(analyser_relaxed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take words which are segmented by the segmenter and count:  \n",
    "\n",
    "```wer``` as ```sum of the best wer for the word / number of words segmented```  \n",
    "```tp``` as ```len(test & ref)```  \n",
    "```fp``` as ```len(test - ref)```  \n",
    "```fn``` as ```len(ref - test)```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gold_std_dict', 'r') as f:\n",
    "    gold_std_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wer import editDistance\n",
    "\n",
    "def get_wer_result(r, h):\n",
    "    res = editDistance(r, h)\n",
    "    return float(res[len(r)][len(h)]) / len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_segmentation(segmenter):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    analysed = 0\n",
    "    not_analysed = 0\n",
    "    wer_score_sum = 0\n",
    "\n",
    "    for word in gold_std_dict:\n",
    "        wer_best = float('+inf')\n",
    "        segmentation = segmenter.lookup(word)\n",
    "    \n",
    "        if not segmentation:\n",
    "            not_analysed += 1\n",
    "            continue\n",
    "        \n",
    "        analysed += 1\n",
    "\n",
    "        test = set()\n",
    "        ref = set(d[word])\n",
    "\n",
    "        for seg in segmentation:\n",
    "            if seg:\n",
    "#                 print(seg)\n",
    "                seg_replaced = re.sub('·+', ' ', seg[0].strip('·'))\n",
    "                test.add(seg_replaced)\n",
    "\n",
    "                for ans in d[word]:\n",
    "                    wer_score = get_wer_result(ans.split(), seg_replaced.split())\n",
    "                    wer_best = min(wer_best, wer_score)\n",
    "\n",
    "        if wer_best < float('+inf'):\n",
    "            wer_score_sum += wer_best\n",
    "    \n",
    "            tp += len(test & ref)\n",
    "            fp += len(test - ref)\n",
    "            fn += len(ref - test)\n",
    "    \n",
    "        else:\n",
    "            print(word, segmentation)\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    fscore = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print('precision: {:.3%} tp: {} fp: {}'.format(precision, tp, fp)),\n",
    "    print('recall: {:.3%} tp: {} fn: {}'.format(recall, tp, fn)),\n",
    "    print('fscore: {:.3%}'.format(fscore))\n",
    "    print('wer: {:.3%}\\n'.format(wer_score_sum / analysed))\n",
    "\n",
    "    print('analysed: {:.3%}'.format(analysed / (analysed + not_analysed)))\n",
    "    print('not_analysed: {:.3%}'.format(not_analysed / (analysed + not_analysed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 18.618% tp: 2223 fp: 9717\n",
      "recall: 51.854% tp: 2223 fn: 2064\n",
      "fscore: 27.399%\n",
      "wer: 32.570%\n",
      "\n",
      "analysed: 54.441%\n",
      "not_analysed: 45.559%\n"
     ]
    }
   ],
   "source": [
    "# everything is counted only for the words which were segmented by the segmenter\n",
    "segmenter = hfst.HfstInputStream('../dev/segmenter/evn.segmenter.hfst').read()\n",
    "evaluate_segmentation(segmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
